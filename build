
clean() {

echo "Removing intermediate images"
docker images | grep none | awk '{ print "docker image rm -f "$3 }' | sh

}

stop() {

echo "Stopping running containers"
docker ps | grep spark | awk '{ print "docker stop "$1 }' | sh

echo "Deleting old container images"
docker ps -a | grep spark | awk '{ print "docker rm -f "$1 }' | sh

}

build() {

echo "Starting to build all containers"

if [ ! -d BUILD_BINARY/spark2 ]
then
    echo "Downloading Spark"
    which wget
    if [ $? -eq 0 ] ; then
        wget https://www-eu.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz
    else
        curl -s -k https://www-eu.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz --output spark-2.4.4-bin-hadoop2.7.tgz
    fi
    echo "Extracting Spark"
    tar -zxvf spark-2.4.4-bin-hadoop2.7.tgz -C BUILD_BINARY/
    mv BUILD_BINARY/spark-2.4.4-bin-hadoop2.7 BUILD_BINARY/spark2
    rm -f spark-2.4.4-bin-hadoop2.7.tgz

    echo "Distributing container specific configuration and scripts"
    cp BUILD_BINARY/conf/* BUILD_BINARY/spark2/conf/
    cp BUILD_BINARY/script/* BUILD_BINARY/spark2/sbin/
fi

echo "Creating Spark Server image"
docker build . -t sanmuk21/sdh-spark-kubernetes:1.0.2.4
#docker push sanmuk21/sdh-spark-kubernetes:1.0.2.4

}

echo "Parameter passed: $1"
[ -z "${1}" ] && exit 0
for i in $(echo ${1} | tr ',' '\n')
do
	${i}
done

